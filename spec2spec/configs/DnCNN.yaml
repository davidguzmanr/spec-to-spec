# pytorch_lightning==1.8.1
seed_everything: 42
trainer:
  logger: true
  enable_checkpointing: true
  devices: 1
  enable_progress_bar: true
  max_epochs: 1000
  max_steps: 100000
  log_every_n_steps: 10
  accelerator: auto
  inference_mode: true
  callbacks:
    - class_path: pytorch_lightning.callbacks.LearningRateMonitor
      init_args:
        logging_interval: epoch
        log_momentum: false
    - class_path: pytorch_lightning.callbacks.ModelCheckpoint
      init_args:
        monitor: val/loss
        save_last: true
        save_top_k: 3
model:
  lr: 0.001
  weight_decay: 0.0
  loss: mse
  vocoder_path: data/generator_universal.pth.tar
  network: DnCNN
  network_kwargs:
    depth: 17
    n_channels: 64
    image_channels: 1
    kernel_size: 3
    padding: 1
data:
  data_dir: data
  train_filelist: data/train.txt
  val_filelist: data/val.txt
  test_filelist: data/test.txt
  sort: true
  split: true
  segment_size: 32
  batch_size: 16
  num_workers: 4
